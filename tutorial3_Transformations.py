import torch
from torchvision import datasets
from torchvision.transforms import ToTensor, Lambda

ds = datasets.FashionMNIST(
    root="data",
    train=True,
    download=True,
    transform=ToTensor(),
    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))
)

# All TorchVision datasets have two parameters -transform to modify the features and target_transform to modify the labels - that accept callables containing the transformation logic
# The FashionMNIST features are in PIL Image format, and the labels are integers. For training, we need the features as normalized tensors, and the labels as one-hot encoded tensors.
# One-hot means the values are all 0 or 1. So convert to a binary system. e.g:
# indices = [0, 1, 2]
#    depth = 3
#    tf.one_hot(indices, depth)  # output: [3 x 3]
    # [[1., 0., 0.],
    #  [0., 1., 0.],
    #  [0., 0., 1.]]
 
#ToTensor converts a PIL image or NumPy ndarray into a FloatTensor. and scales the imageâ€™s pixel intensity values in the range [0., 1.]


#Lambda transforms apply any user-defined lambda function. Here, we define a function to turn the integer into a one-hot encoded tensor. It first creates a zero tensor of size 10 (the number of labels in our dataset) and calls scatter_ which assigns a value=1 on the index as given by the label y.
